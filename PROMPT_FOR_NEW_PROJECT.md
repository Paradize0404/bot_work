# Промпт: OCR российских бухгалтерских документов через Vision LLM

Скопируй всё ниже в начало нового чата:

---

## Что я делаю

модуль для автоматического распознавания бумажных накладных/чеков/рко/и прочих документов (фото → структурированные данные → загрузка в учётную систему ресторана).

**Общий flow:**
1. Сотрудник фотографирует бумажную накладную → отправляет в Telegram
2. Vision LLM (Gemini) распознаёт фото → возвращает структурированный JSON
3. Распознанные данные маппятся на справочники учётной системы (поставщики, товары, склады) через **fuzzy matching** Нужно создать гугл таблицу в которую будут попадать все новые распознанные товары которых еще нет в этой таблице а напротив них будут выпадающие списки с номенклатурой по группе товары 
4. При первом появлении нового поставщика/товара — бот отпарвляет  пользователя в гугл таблицу чтобы он замэпил все и ждет пока пользователь нажмет готово, после чего еще раз мэпит и если все ок то заносит в систему , 
5. Формируется документ → на подтверждение бухгалтеру → отправка в учётную систему

---

## Ключевые принципы (проработаны, проверены на практике)

### 1. OCR через Vision LLM, не через классический OCR

- **Почему не Google Vision / Yandex OCR / Tesseract:** классический OCR возвращает сырой текст. Дальше нужен regex-парсер на 2000+ строк для каждого типа документа. LLM делает OCR + парсинг + структурирование в один шаг → сразу JSON.
- **Тестировались модели (февраль 2026):** GPT-4o-mini (плохо), GPT-4o, GPT-4.1 (хорошо), GPT-5.2 (лучший). Рекомендую также тестировать Gemini 3 flash prewiev.
- **Стоимость:** Gemini Flash — почти бесплатно.
- **temperature=0.1** — минимизируем креативность, максимизируем точность.
- **detail=high** — для мелкого текста в таблицах.

### 2. Обучаемый маппинг (самообучение без fine-tune)

 **нельзя** дообучить (fine-tune для vision нет). Но система учится через маппинг:

```
raw_name (как распознал LLM) → corrected_name (как правильно) → entity_id (UUID в учётной системе)
```

- Много вариантов `raw_name` → один `corrected_name` → один `entity_id`
- Новые распознанные названия автоматически сохраняются в БД
- Fuzzy match (fuzzywuzzy, порог ~85%) — если похоже на уже известное, подставляем автоматически
- Если не нашли — спрашиваем пользователя, запоминаем
- Через 50–100 документов система почти всё распознаёт без вопросов

Пример для товаров:
| raw_name (LLM распознал) | corrected_name | entity_id |
|---|---|---|
| Помидор свеж. | Помидоры свежие | uuid-123 |
| Томаты свежие | Помидоры свежие | uuid-123 |
| Помидоры св. | Помидоры свежие | uuid-123 |

Тот же подход для поставщиков, покупателей, адресов.

### 3. Валидация + автоисправление после OCR

LLM допускает ошибки в числах. Математическая проверка ловит ~30% из них:

```python
# sum = qty × price
expected = round(item["qty"] * item["price"], 2)
if abs(item["sum_without_vat"] - expected) > 0.1:
    item["sum_without_vat"] = expected

# НЕ перезаписываем, а помечаем
if abs(item["sum_without_vat"] - item["qty"] * item["price"]) > 0.5:
    item["_warning"] = "Сумма не сходится с qty×price"

# total = сумма всех позиций
invoice["total_without_vat"] = sum(i["sum_without_vat"] for i in items)
```

### 4. Подсовываем известные списки в промпт

LLM галлюцинирует при чтении размытого текста — подставляет реально существующие похожие слова:
- "Клиническая 83А" → галлюцинирует "Каширская", "Кимишевская", "Кишиневские"

**Решение:** так же выводим в таблицу и мэпим склад 

```

LLM перестаёт угадывать и **выбирает из списка** → точность ~99%.

Тот же подход для поставщиков: если в БД 50+ известных поставщиков — передаём список, LLM матчит.

### 5. Названия товаров — ТОЧНО как на фото + нормализованная версия

Промпт просит два поля:
```json
{
  "name": "Помидор свеж.",           // точно как на фото
  "name_normalized": "Помидоры свежие"  // стандартное название
}
```
`name` — оригинал для отладки. `name_normalized` — для fuzzy match по справочникам.

### 6. Промпт для OCR — ключевые правила

```
- Цифры — числами, не строками 
- НИКОГДА не используй разделители тысяч: 73221.82 а не 73,221.82 или 73_221.82
- Если не можешь прочитать — предупреждай 
- Если таблица обрезана или недостает листа , проси перефоткать 
- Названия товаров пиши ТОЧНО как на фото
- Формат ответа — строго JSON, без markdown, без ```json
```

---

## Типы российских бухгалтерских документов

- **УПД** (Универсальный передаточный документ / счёт-фактура) — основной
- **Кассовый чек** — мелкие покупки за наличные
- **РКО** (Расходный кассовый ордер)
- **Акт выполненных работ/услуг**
- **Товарный чек**
так же могут быть новые нестандартные 

Каждый — разная структура. LLM определяет тип и адаптирует вывод.

---

## Формат JSON от LLM

```json
делаем по документации айки по загрузке приходных накладных 
```

---

## Стратегии улучшения точности (по приоритету)

| # | Стратегия | Эффект | Сложность |
|---|---|---|---|
| 1 | **Валидация + автоисправление** — математические проверки qty×price=sum, НДС, итоги | +20-30% | Низкая |
| 2 | **Feedback loop** — сохранять сырое + исправленное, fuzzy match по исправленным | +30-50% со временем | Средняя |
| 3 | **Итеративное улучшение промпта** — добавлять правила на каждую обнаруженную ошибку | +10-20% на итерацию | Низкая |
| 4 | **Подсовывание списков** — известные поставщики/покупатели/товары в промпт | +15-20% для известных | Низкая |
| 5 | **Предобработка изображений** — ч/б, контраст ×2, резкость ×2 | +5-10% для плохих фото | Низкая |
| 6 | **name + name_normalized** — два поля в JSON, fuzzy match по нормализованному | +10-15% | Низкая |
| 7 | **Few-shot примеры** — 2-3 эталонных пары фото→JSON в промпте | +10-15% (но +токены) | Низкая |
| 8 | **Двойной прогон** — отправить дважды, сравнить, показать расхождения | +5% edge cases | Низкая (×2 цена) |

---

## Известные проблемы Vision LLM на накладных

| Проблема | Как проявляется | Решение |
|---|---|---|
| Разделители тысяч | `1_144.46`, `73,221.82` | Правило в промпте + regex постобработка |
| Галлюцинации названий | "Клиническая" → "Каширская" | Обучаемый маппинг + fuzzy |
| Разное написание товаров | "Помидор свеж." / "Томаты" | Обучаемый маппинг + fuzzy |
| Ошибки в числах | qty=10 вместо 1.0 | Валидация sum=qty×price |
| Многостраничные документы | Фото 1/3 обрезано | page_info + merge по doc_number |
| Мелкий текст в таблицах | Пропуск строк | detail=high + предобработка |
многостаничные документы мы находим первую страницу и ищем где продолжается нумерация и присутствует тот же поставщик или какие-либо другие идентификаторы , чтобы определить следующий лист , если присутствует только один лист из многостраничной , то просим пользователя дослать 
---



---

## Архитектурные принципы

1. **OCR-адаптер изолирован** — один файл, легко заменить нейросеть
2. **Тонкие хэндлеры** — Telegram-хэндлеры только управляют flow, бизнес-логика отдельно
3. **Маппинг = use case** — fuzzy-поиск + UPSERT в БД
4. **Никакого хардкода** — секреты в .env,либо в гугл таблице , либо на рейл вей 
5. **UPSERT-паттерн** — INSERT ON CONFLICT DO UPDATE для маппингов
6. **бухгалтерское  подтверждение** — документ отправляется в учётную систему только после одобрения
7. **Автокоммит после правок** — после внесения изменений в код автоматически делать `git add .` и `git commit -m "описание изменений"` для сохранения истории работы

---

## Язык общения: русский

