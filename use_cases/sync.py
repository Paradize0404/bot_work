"""
Use-cases: —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ iiko ‚Üí PostgreSQL.

–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞:
  _run_sync()     ‚Äî –µ–¥–∏–Ω—ã–π —à–∞–±–ª–æ–Ω: fetch API ‚Üí map ‚Üí batch upsert ‚Üí sync_log
  batch_upsert()  ‚Äî generic INSERT ‚Ä¶ ON CONFLICT DO UPDATE –±–∞—Ç—á–∞–º–∏ –ø–æ BATCH_SIZE
  _map_*()        ‚Äî –º–∞–ø–ø–∏–Ω–≥ dict –∏–∑ API ‚Üí dict –¥–ª—è —Ç–∞–±–ª–∏—Ü—ã
"""

import asyncio
import logging
import time
import uuid
from typing import Any, Callable, Coroutine

from sqlalchemy import delete as sa_delete
from sqlalchemy.dialects.postgresql import insert as pg_insert
from sqlalchemy.ext.asyncio import AsyncSession

from adapters import iiko_api
from db.engine import async_session_factory
from db.models import (
    ENTITY_ROOT_TYPES,
    Department,
    Employee,
    EmployeeRole,
    Entity,
    GroupDepartment,
    Product,
    ProductGroup,
    Store,
    Supplier,
    SyncLog,
)
from use_cases._helpers import safe_uuid, safe_bool, safe_decimal, now_kgd

logger = logging.getLogger(__name__)

BATCH_SIZE = 500

RowMapper = Callable[[dict, Any], dict | None]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Generic batch upsert
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def batch_upsert(
    table,
    rows: list[dict],
    conflict_target: list[str] | str,
    label: str,
    session: AsyncSession,
) -> int:
    """
    INSERT ... VALUES (...),(...) ON CONFLICT DO UPDATE
    –±–∞—Ç—á–∞–º–∏ –ø–æ BATCH_SIZE.

    conflict_target:
      - list[str]  ‚Üí index_elements  (–ø—Ä–æ—Å—Ç–æ–π PK/unique index)
      - str        ‚Üí constraint name (—Å–æ—Å—Ç–∞–≤–Ω–æ–π unique constraint)

    SET-clause —Å—Ç—Ä–æ–∏—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –∫–ª—é—á–µ–π rows (–º–∏–Ω—É—Å conflict-–∫–æ–ª–æ–Ω–∫–∏).
    """
    if not rows:
        return 0

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º exclude-–∫–æ–ª–æ–Ω–∫–∏ –¥–ª—è SET
    if isinstance(conflict_target, str):
        # constraint name ‚Äî exclude –Ω–µ –Ω—É–∂–µ–Ω, PG —Å–∞–º —Ä–∞–∑–±–µ—Ä—ë—Ç—Å—è
        conflict_kw = {"constraint": conflict_target}
        exclude = set()   # –æ–±–Ω–æ–≤–ª—è–µ–º –≤—Å—ë –∫—Ä–æ–º–µ —Å—É—Ä—Ä–æ–≥–∞—Ç–Ω–æ–≥–æ pk
    else:
        conflict_kw = {"index_elements": conflict_target}
        exclude = set(conflict_target)

    # –ö–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–ª—è—Ç—å
    skip = exclude | {"pk"}

    for offset in range(0, len(rows), BATCH_SIZE):
        batch = rows[offset : offset + BATCH_SIZE]
        stmt = pg_insert(table).values(batch)
        stmt = stmt.on_conflict_do_update(
            **conflict_kw,
            set_={k: getattr(stmt.excluded, k) for k in batch[0] if k not in skip},
        )
        await session.execute(stmt)
        done = min(offset + BATCH_SIZE, len(rows))
        logger.info("[%s] Batch: %d / %d", label, done, len(rows))

    return len(rows)


async def mirror_delete(
    table,
    id_column: str,
    valid_ids: set,
    label: str,
    session: AsyncSession,
    extra_filters: dict[str, Any] | None = None,
) -> int:
    """
    –ó–µ—Ä–∫–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞: —É–¥–∞–ª–∏—Ç—å –∏–∑ –ë–î –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –Ω–µ—Ç –≤ API.
    DELETE FROM table WHERE id_column NOT IN (valid_ids)
    [AND extra_filter_col = val ...]

    –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:
      - –µ—Å–ª–∏ valid_ids –ø—É—Å—Ç (API –≤–µ—Ä–Ω—É–ª 0) ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
      - –µ—Å–ª–∏ —É–¥–∞–ª–∏—Ç—å –ø—Ä–∏—à–ª–æ—Å—å –±—ã >50% –∑–∞–ø–∏—Å–µ–π ‚Äî —ç—Ç–æ –∞–Ω–æ–º–∞–ª–∏—è, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    """
    if not valid_ids:
        logger.warning("[%s] Mirror-delete –ø—Ä–æ–ø—É—â–µ–Ω: –ø—É—Å—Ç–æ–π –Ω–∞–±–æ—Ä ID –∏–∑ API", label)
        return 0

    # –ü–æ–¥—Å—á—ë—Ç —Ç–µ–∫—É—â–∏—Ö –∑–∞–ø–∏—Å–µ–π –¥–ª—è sanity-check
    from sqlalchemy import func as sa_func, select as sa_select
    col = table.c[id_column]

    count_stmt = sa_select(sa_func.count()).select_from(table)
    if extra_filters:
        for col_name, val in extra_filters.items():
            count_stmt = count_stmt.where(table.c[col_name] == val)
    total_in_db = (await session.execute(count_stmt)).scalar() or 0

    to_stay = len(valid_ids)
    to_delete = max(0, total_in_db - to_stay)

    if total_in_db > 0 and to_delete > total_in_db * 0.5:
        logger.error(
            "[%s] Mirror-delete –ó–ê–ë–õ–û–ö–ò–†–û–í–ê–ù: —É–¥–∞–ª–∏–ª–∏ –±—ã %d –∏–∑ %d (>50%%). "
            "–í–æ–∑–º–æ–∂–µ–Ω —Å–±–æ–π API ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º.",
            label, to_delete, total_in_db,
        )
        return 0

    stmt = sa_delete(table).where(col.notin_(list(valid_ids)))
    if extra_filters:
        for col_name, val in extra_filters.items():
            stmt = stmt.where(table.c[col_name] == val)

    result = await session.execute(stmt)
    count = result.rowcount
    if count:
        logger.info("[%s] Mirror-delete: —É–¥–∞–ª–µ–Ω–æ %d –∑–∞–ø–∏—Å–µ–π (–Ω–µ—Ç –≤ API)", label, count)
    else:
        logger.debug("[%s] Mirror-delete: —É–¥–∞–ª—è—Ç—å –Ω–µ—á–µ–≥–æ", label)
    return count


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Generic sync runner
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def _run_sync(
    label: str,
    fetch_coro: Coroutine,
    table,
    mapper: RowMapper,
    conflict_target: list[str] | str,
    triggered_by: str | None = None,
    pk_column: str = "id",
    mirror_scope: dict[str, Any] | None = None,
) -> int:
    """
    –ï–¥–∏–Ω—ã–π —à–∞–±–ª–æ–Ω —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏:
      1. await fetch_coro      ‚Äî –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ iiko API
      2. mapper()              ‚Äî dict API ‚Üí dict –ë–î  (None = –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å)
      3. batch_upsert()        ‚Äî batch INSERT ON CONFLICT
      4. SyncLog               ‚Äî –≤ —Ç–æ–π –∂–µ —Å–µ—Å—Å–∏–∏ (0 –ª–∏—à–Ω–∏—Ö round-trip)
    """
    started = now_kgd()
    t0 = time.monotonic()
    logger.info("[%s] –ù–∞—á–∏–Ω–∞—é —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—é...", label)

    try:
        items = await fetch_coro
        t_api = time.monotonic() - t0
        logger.info("[%s] API: %d –∑–∞–ø–∏—Å–µ–π –∑–∞ %.1f —Å–µ–∫", label, len(items), t_api)

        now = now_kgd()
        rows = [r for item in items if (r := mapper(item, now)) is not None]
        skipped = len(items) - len(rows)
        if skipped:
            logger.warning("[%s] –ü—Ä–æ–ø—É—â–µ–Ω–æ %d (–Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π UUID)", label, skipped)

        t1 = time.monotonic()
        async with async_session_factory() as session:
            count = await batch_upsert(table, rows, conflict_target, label, session)
            # Mirror-delete: —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏, –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –Ω–µ—Ç –≤ API
            valid_ids = {r[pk_column] for r in rows if r.get(pk_column) is not None}
            deleted = await mirror_delete(
                table, pk_column, valid_ids, label, session, mirror_scope,
            )
            # sync_log –≤ —Ç–æ–π –∂–µ —Å–µ—Å—Å–∏–∏ ‚Äî —ç–∫–æ–Ω–æ–º–∏–º 1 round-trip
            session.add(SyncLog(
                entity_type=label,
                started_at=started,
                finished_at=now_kgd(),
                status="success",
                records_synced=count,
                triggered_by=triggered_by,
            ))
            await session.commit()

        logger.info("[%s] –ë–î: upsert %d, —É–¥–∞–ª–µ–Ω–æ %d –∑–∞ %.1f —Å–µ–∫ | –ò—Ç–æ–≥–æ %.1f —Å–µ–∫",
                    label, count, deleted, time.monotonic() - t1, time.monotonic() - t0)
        return count

    except Exception as exc:
        logger.exception("[%s] –û–®–ò–ë–ö–ê: %s", label, exc)
        try:
            async with async_session_factory() as session:
                session.add(SyncLog(
                    entity_type=label,
                    started_at=started,
                    finished_at=now_kgd(),
                    status="error",
                    error_message=str(exc)[:2000],
                    triggered_by=triggered_by,
                ))
                await session.commit()
        except Exception:
            logger.exception("[%s] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –æ—à–∏–±–∫—É –≤ sync_log", label)
        raise


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Row mappers  (dict API ‚Üí dict DB;  None = skip)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def _entity_mapper(root_type: str) -> RowMapper:
    """–§–∞–±—Ä–∏–∫–∞ –º–∞–ø–ø–µ—Ä–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ rootType."""
    def _map(item: dict, now) -> dict | None:
        uid = safe_uuid(item.get("id"))
        if not uid:
            return None
        return {
            "id": uid, "root_type": root_type,
            "name": item.get("name"), "code": item.get("code"),
            "deleted": safe_bool(item.get("deleted", False)),
            "synced_at": now, "raw_json": item,
        }
    return _map


def _map_supplier(item: dict, now) -> dict | None:
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    return {
        "id": uid, "name": item.get("name"), "code": item.get("code"),
        "deleted": safe_bool(item.get("deleted", False)),
        "card_number": item.get("cardNumber"),
        "taxpayer_id_number": item.get("taxpayerIdNumber"),
        "snils": item.get("snils"),
        "synced_at": now, "raw_json": item,
    }


def _map_corporate(item: dict, now) -> dict | None:
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    return {
        "id": uid, "parent_id": safe_uuid(item.get("parentId")),
        "name": item.get("name"), "code": item.get("code"),
        "department_type": item.get("type"),
        "deleted": safe_bool(item.get("deleted", False)),
        "synced_at": now, "raw_json": item,
    }


def _map_product(item: dict, now) -> dict | None:
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    return {
        "id": uid, "parent_id": safe_uuid(item.get("parent")),
        "name": item.get("name"), "code": item.get("code"),
        "num": item.get("num"), "description": item.get("description"),
        "product_type": item.get("type"),
        "deleted": safe_bool(item.get("deleted", False)),
        "main_unit": safe_uuid(item.get("mainUnit")),
        "category": safe_uuid(item.get("category")),
        "accounting_category": safe_uuid(item.get("accountingCategory")),
        "tax_category": safe_uuid(item.get("taxCategory")),
        "default_sale_price": safe_decimal(item.get("defaultSalePrice")),
        "unit_weight": safe_decimal(item.get("unitWeight")),
        "unit_capacity": safe_decimal(item.get("unitCapacity")),
        "synced_at": now, "raw_json": item,
    }


def _map_product_group(item: dict, now) -> dict | None:
    """–ú–∞–ø–ø–∏–Ω–≥ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–Ω–æ–π –≥—Ä—É–ø–ø—ã –∏–∑ iiko API ‚Üí –ë–î."""
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    return {
        "id": uid,
        "parent_id": safe_uuid(item.get("parent")),
        "name": item.get("name"),
        "code": item.get("code"),
        "num": item.get("num"),
        "description": item.get("description"),
        "deleted": safe_bool(item.get("deleted", False)),
        "category": safe_uuid(item.get("category")),
        "accounting_category": safe_uuid(item.get("accountingCategory")),
        "tax_category": safe_uuid(item.get("taxCategory")),
        "synced_at": now, "raw_json": item,
    }


def _map_employee(item: dict, now) -> dict | None:
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    parts = [item[f] for f in ("lastName", "firstName", "middleName") if item.get(f)]
    return {
        "id": uid,
        "name": " ".join(parts) if parts else item.get("name"),
        "code": item.get("code"),
        "deleted": safe_bool(item.get("deleted", False)),
        "first_name": item.get("firstName"),
        "middle_name": item.get("middleName"),
        "last_name": item.get("lastName"),
        "role_id": safe_uuid(item.get("mainRoleId")),
        "synced_at": now, "raw_json": item,
    }


def _map_role(item: dict, now) -> dict | None:
    uid = safe_uuid(item.get("id"))
    if not uid:
        return None
    return {
        "id": uid, "name": item.get("name"), "code": item.get("code"),
        "deleted": safe_bool(item.get("deleted", False)),
        "payment_per_hour": safe_decimal(item.get("paymentPerHour")),
        "steady_salary": safe_decimal(item.get("steadySalary")),
        "schedule_type": item.get("scheduleType"),
        "synced_at": now, "raw_json": item,
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Public API  (1 —Ñ—É–Ω–∫—Ü–∏—è = 1 –∫–Ω–æ–ø–∫–∞ –±–æ—Ç–∞)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def sync_entity_list(root_type: str, triggered_by: str | None = None) -> int:
    if root_type not in ENTITY_ROOT_TYPES:
        raise ValueError(f"Unknown rootType: {root_type}")
    return await _run_sync(
        root_type, iiko_api.fetch_entities(root_type),
        Entity.__table__, _entity_mapper(root_type),
        "uq_entity_id_root_type", triggered_by,
        mirror_scope={"root_type": root_type},
    )


async def sync_all_entities(triggered_by: str | None = None) -> dict[str, int]:
    """Fetch all 16 rootTypes in parallel, upsert in one transaction."""
    t0 = time.monotonic()
    started = now_kgd()

    # 1) –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∑–∞–±–∏—Ä–∞–µ–º –≤—Å–µ 16 —Ç–∏–ø–æ–≤ –∏–∑ API
    logger.info("=== –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: –∑–∞–≥—Ä—É–∂–∞—é %d —Ç–∏–ø–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ===", len(ENTITY_ROOT_TYPES))
    coros = [iiko_api.fetch_entities(rt) for rt in ENTITY_ROOT_TYPES]
    fetched = dict(zip(
        ENTITY_ROOT_TYPES,
        await asyncio.gather(*coros, return_exceptions=True),
    ))
    t_api = time.monotonic() - t0
    logger.info("=== API: –≤—Å–µ %d —Ç–∏–ø–æ–≤ –∑–∞ %.1f —Å–µ–∫ ===", len(ENTITY_ROOT_TYPES), t_api)

    # 2) –ú–∞–ø–ø–∏–º –≤—Å–µ –≤ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –ë–î
    now = now_kgd()
    results: dict[str, int] = {}
    all_rows: list[dict] = []

    for rt in ENTITY_ROOT_TYPES:
        items = fetched[rt]
        if isinstance(items, BaseException):
            logger.error("[%s] –û—à–∏–±–∫–∞ API: %s", rt, items)
            results[rt] = -1
            continue
        mapper = _entity_mapper(rt)
        rows = [r for item in items if (r := mapper(item, now)) is not None]
        all_rows.extend(rows)
        results[rt] = len(rows)
        logger.info("[%s] %d –∑–∞–ø–∏—Å–µ–π", rt, len(rows))

    # 3) –û–¥–∏–Ω batch INSERT + sync_log –¥–ª—è –≤—Å–µ—Ö ‚Äî 1 COMMIT
    t1 = time.monotonic()
    async with async_session_factory() as session:
        total = await batch_upsert(
            Entity.__table__, all_rows, "uq_entity_id_root_type", "entities_all", session,
        )
        # Mirror-delete: —É–¥–∞–ª–∏—Ç—å –∑–∞–ø–∏—Å–∏ –ø–æ root_type, –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª—å—à–µ –Ω–µ—Ç –≤ API
        total_deleted = 0
        for rt in ENTITY_ROOT_TYPES:
            raw = fetched[rt]
            if isinstance(raw, BaseException):
                continue
            rt_ids = {safe_uuid(item.get("id")) for item in raw} - {None}
            if rt_ids:
                total_deleted += await mirror_delete(
                    Entity.__table__, "id", rt_ids,
                    f"entity:{rt}", session,
                    extra_filters={"root_type": rt},
                )

        for rt, cnt in results.items():
            session.add(SyncLog(
                entity_type=rt,
                started_at=started,
                finished_at=now_kgd(),
                status="success" if cnt >= 0 else "error",
                records_synced=cnt if cnt >= 0 else None,
                error_message=str(fetched[rt])[:2000] if cnt < 0 else None,
                triggered_by=triggered_by,
            ))
        await session.commit()

    ok = sum(1 for v in results.values() if v >= 0)
    logger.info(
        "=== –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: %d ok, %d err | %d –∑–∞–ø–∏—Å–µ–π, —É–¥–∞–ª–µ–Ω–æ %d | %.1f —Å–µ–∫ (API %.1f + –ë–î %.1f) ===",
        ok, len(results) - ok, total, total_deleted,
        time.monotonic() - t0, t_api, time.monotonic() - t1,
    )
    return results


async def sync_suppliers(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "Supplier", iiko_api.fetch_suppliers(),
        Supplier.__table__, _map_supplier, ["id"], triggered_by,
    )


async def sync_departments(triggered_by: str | None = None) -> int:
    count = await _run_sync(
        "Department", iiko_api.fetch_departments(),
        Department.__table__, _map_corporate, ["id"], triggered_by,
    )
    # –û–±–Ω–æ–≤–ª—è–µ–º —Å–ø–∏—Å–æ–∫ –∑–∞–≤–µ–¥–µ–Ω–∏–π –¥–ª—è –∑–∞—è–≤–æ–∫ –≤ GSheet
    try:
        from use_cases.product_request import sync_request_stores_sheet
        await sync_request_stores_sheet()
    except Exception:
        logger.warning("[Department] –û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –∑–∞–≤–µ–¥–µ–Ω–∏–π ‚Üí GSheet –ù–∞—Å—Ç—Ä–æ–π–∫–∏", exc_info=True)
    return count


async def sync_stores(triggered_by: str | None = None) -> int:
    count = await _run_sync(
        "Store", iiko_api.fetch_stores(),
        Store.__table__, _map_corporate, ["id"], triggered_by,
    )
    return count


async def sync_groups(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "Group", iiko_api.fetch_groups(),
        GroupDepartment.__table__, _map_corporate, ["id"], triggered_by,
    )


async def sync_product_groups(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "ProductGroup", iiko_api.fetch_product_groups(),
        ProductGroup.__table__, _map_product_group, ["id"], triggered_by,
    )


async def sync_products(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "Product", iiko_api.fetch_products(include_deleted=False),
        Product.__table__, _map_product, ["id"], triggered_by,
    )


async def sync_employees(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "Employee", iiko_api.fetch_employees(include_deleted=False),
        Employee.__table__, _map_employee, ["id"], triggered_by,
    )


async def sync_employee_roles(triggered_by: str | None = None) -> int:
    return await _run_sync(
        "EmployeeRole", iiko_api.fetch_employee_roles(),
        EmployeeRole.__table__, _map_role, ["id"], triggered_by,
    )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# –û—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è –¥–ª—è handler'–æ–≤ (–±–∏–∑–Ω–µ—Å-–ª–æ–≥–∏–∫–∞ –æ—Ç—á—ë—Ç–æ–≤)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

async def sync_all_iiko_with_report(
    triggered_by: str,
) -> list[str]:
    """
    –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è iiko ‚Äî —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ + –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–æ–∫ –æ—Ç—á—ë—Ç–∞ (–¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ Telegram).
    """
    report: list[str] = []

    # 1) –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏ (—É–∂–µ –≤–Ω—É—Ç—Ä–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ)
    try:
        results = await sync_all_entities(triggered_by=triggered_by)
        total = sum(v for v in results.values() if v >= 0)
        errors = sum(1 for v in results.values() if v < 0)
        report.append(f"üìã –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: {total} –∑–∞–ø–∏—Å–µ–π, –æ—à–∏–±–æ–∫: {errors}")
    except Exception:
        report.append("üìã –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: ‚ùå –æ—à–∏–±–∫–∞")

    # 2) –û—Å—Ç–∞–ª—å–Ω—ã–µ 8 ‚Äî –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —á–µ—Ä–µ–∑ asyncio.gather
    sync_tasks = [
        ("üè¢ –ü–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è", sync_departments),
        ("üè™ –°–∫–ª–∞–¥—ã", sync_stores),
        ("üë• –ì—Ä—É–ø–ø—ã", sync_groups),
        ("üìÅ –ù–æ–º.–≥—Ä—É–ø–ø—ã", sync_product_groups),
        ("üì¶ –ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", sync_products),
        ("üöö –ü–æ—Å—Ç–∞–≤—â–∏–∫–∏", sync_suppliers),
        ("üë∑ –°–æ—Ç—Ä—É–¥–Ω–∏–∫–∏", sync_employees),
        ("üé≠ –î–æ–ª–∂–Ω–æ—Å—Ç–∏", sync_employee_roles),
    ]
    coros = [func(triggered_by=triggered_by) for _, func in sync_tasks]
    results_list = await asyncio.gather(*coros, return_exceptions=True)

    for (label, _), result in zip(sync_tasks, results_list):
        if isinstance(result, BaseException):
            report.append(f"{label}: ‚ùå {result}")
        else:
            report.append(f"{label}: ‚úÖ {result} –∑–∞–ø–∏—Å–µ–π")

    return report


async def sync_everything_with_report(
    triggered_by: str,
) -> tuple[list[str], list[str]]:
    """
    –ü–æ–ª–Ω–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è iiko + FinTablo –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (iiko_lines, ft_lines) –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è.
    """
    from use_cases import sync_fintablo as ft_uc

    async def _iiko_rest():
        tasks = [
            sync_departments, sync_stores, sync_groups,
            sync_product_groups, sync_products, sync_suppliers,
            sync_employees, sync_employee_roles,
        ]
        return await asyncio.gather(
            *[f(triggered_by=triggered_by) for f in tasks],
            return_exceptions=True,
        )

    iiko_entities_r, iiko_rest_r, ft_r = await asyncio.gather(
        sync_all_entities(triggered_by=triggered_by),
        _iiko_rest(),
        ft_uc.sync_all_fintablo(triggered_by=triggered_by),
        return_exceptions=True,
    )

    # ‚îÄ‚îÄ iiko lines ‚îÄ‚îÄ
    iiko_lines: list[str] = []
    if isinstance(iiko_entities_r, BaseException):
        iiko_lines.append("  üìã –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: ‚ùå")
    else:
        total = sum(v for v in iiko_entities_r.values() if v >= 0)
        iiko_lines.append(f"  üìã –°–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∏: ‚úÖ {total}")

    iiko_labels = [
        "üè¢ –ü–æ–¥—Ä–∞–∑–¥.", "üè™ –°–∫–ª–∞–¥—ã", "üë• –ì—Ä—É–ø–ø—ã", "üìÅ –ù–æ–º.–≥—Ä—É–ø–ø—ã",
        "üì¶ –ù–æ–º–µ–Ω–∫–ª.", "üöö –ü–æ—Å—Ç–∞–≤—â.", "üë∑ –°–æ—Ç—Ä—É–¥–Ω.", "üé≠ –î–æ–ª–∂–Ω–æ—Å—Ç–∏",
    ]
    if isinstance(iiko_rest_r, BaseException):
        for lb in iiko_labels:
            iiko_lines.append(f"  {lb}: ‚ùå")
    else:
        for lb, r in zip(iiko_labels, iiko_rest_r):
            iiko_lines.append(f"  {lb}: {'‚úÖ ' + str(r) if isinstance(r, int) else '‚ùå'}")

    # ‚îÄ‚îÄ FinTablo lines ‚îÄ‚îÄ
    ft_lines: list[str] = []
    if isinstance(ft_r, BaseException):
        ft_lines.append("  ‚ùå –û—à–∏–±–∫–∞")
    else:
        for label, result in ft_r:
            if isinstance(result, int):
                ft_lines.append(f"  {label}: ‚úÖ {result}")
            else:
                ft_lines.append(f"  {label}: {result}")

    return iiko_lines, ft_lines


async def bg_sync_for_documents(triggered_by: str) -> None:
    """–§–æ–Ω–æ–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –∏ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ —Ä–∞–∑–¥–µ–ª–∞ –î–æ–∫—É–º–µ–Ω—Ç—ã."""
    logger.info("[bg] –§–æ–Ω–æ–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è —Å—Ç–∞—Ä—Ç (%s)", triggered_by)
    try:
        await asyncio.gather(
            sync_products(triggered_by=triggered_by),
            sync_all_entities(triggered_by=triggered_by),
            return_exceptions=True,
        )
        logger.info("[documents] –§–æ–Ω–æ–≤–∞—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã + —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ (%s)", triggered_by)
    except Exception:
        logger.warning("[documents] –û—à–∏–±–∫–∞ —Ñ–æ–Ω–æ–≤–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏", exc_info=True)
